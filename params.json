{"name":"Pml-courseproject","tagline":"","body":"### Practical Machine Learning Course Project Report\r\n### Synoposis\r\nIn this course project, the goal is to use data from accelerometers on the belt, forearm, arm and dumbell of 6 participants, to predict the manner in which they did the barbell lifts. Prediction models were built using the training data set to predict the \"classe\" variable. Based on the cross validation and out-of-sample error, the model built with random forest algorithm performed the best and was selected. This prediction model was used to predict the 20 different test cases.\r\n\r\n### Data Processing\r\nThe training data and test data for this proeject are downloaded from the course website, https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv, https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv. The weight lifting excercies dataset is from Velloso et al, 2013 [1].\r\n\r\n#### Reading in the data\r\nThe training and test data were read from .csv files. The data is comma-seperated format with fields that are blank, \"NA\" and \"#DIV/0!\" as missing values.\r\n\r\n```{r}\r\nlibrary(knitr)\r\ntrainingData <- read.csv(\"pml-training.csv\", header=TRUE,na.strings=c(\"\",\"NA\",\"#DIV/0!\"))\r\ntestData <- read.csv(\"pml-testing.csv\", header=TRUE,na.strings=c(\"\",\"NA\",\"#DIV/0!\"))\r\n```\r\n\r\n#### Preprocessing the data\r\nIn the datasets, the columns with at least a missing value were ignored. The first 7 columns: \"X\", \"user_name\", \"raw_timestamp_part_1\", \"raw_timestamp_part_2\", \"cvtd_timestamp\", \"new_window\" and \"num_window\" were ignored due to the irrelevancy to the classificaiton. \r\n\r\n```{r}\r\ntrainingData <- trainingData[, colSums(is.na(trainingData)) == 0]\r\ntestData <- testData[, colSums(is.na(testData)) == 0]\r\ntrainingData <- trainingData[,-c(1:7)]\r\ntestData <- testData[,-c(1:7)]\r\ndim(trainingData)\r\n# Set an overal random seed.\r\nset.seed(32343)\r\n```\r\n#### Cross-validation and out-of-sample error\r\n\r\n```{r}\r\nlibrary(lattice)\r\nlibrary(ggplot2)\r\nlibrary(caret)\r\n### Split training data to training/testing for one time cross-validation\r\ninTrain <- createDataPartition(y=trainingData$classe, p=0.75, list=FALSE)\r\ntraining <- trainingData[inTrain,]\r\ntesting <- trainingData[-inTrain,]\r\n\r\n### predicting with Decision Trees\r\nlibrary(rpart)\r\nlibrary(rattle)\r\nlibrary(rpart.plot)\r\nmodelFit1 <- train(classe ~., data=training, method=\"rpart\")\r\nfancyRpartPlot(modelFit1$finalModel)\r\npredictions1 <- predict(modelFit1,newdata=testing)\r\nconfusionMatrix(predictions1,testing$classe)\r\nerror1 <- 1 - confusionMatrix(predictions1,testing$classe)$overall[[1]]\r\n\r\n### predicting with Random Forest\r\nlibrary(randomForest)\r\nmodelFit2 <- randomForest(classe ~ ., data=training, importance=TRUE, ntrees=10)\r\npredictions2 <- predict(modelFit2,newdata=testing)\r\nconfusionMatrix(predictions2,testing$classe)\r\nerror2 <- 1 - confusionMatrix(predictions2,testing$classe)$overall[[1]]\r\n```\r\nThe model built using \"rpart\" gives an expected out-of-sample error of `r error1`, and the model built using \"randomForest\" gives an expected out-of-sample error of `r error2`, which is close to zero. Therefore, the random forest model was selected to predict the 20 cases in the test data set.\r\n\r\n```{r}\r\n### predicting the test set\r\nanswers <- predict(modelFit2,newdata=testData)\r\nanswers\r\n\r\npml_write_files = function(x){\r\n  n = length(x)\r\n  for(i in 1:n){\r\n    filename = paste0(\"problem_id_\",i,\".txt\")\r\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\r\n  }\r\n}\r\n\r\npml_write_files(answers)\r\n\r\n```\r\nThe prediction results each in a file were submitted to the programming assignment for automated grading.\r\n\r\n### References\r\n[1] Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}